from pyspark.sql.types import StructType, StructField, IntegerType, StringType
import pyspark.sql.functions as F

# --------------------------------------------------------------------------- #
# Param√®tres √† renseigner
# --------------------------------------------------------------------------- #
storage_account_name  = "<storage‚Äëaccount‚Äëname>"
storage_account_key   = "<storage‚Äëaccount‚Äëkey>"
container             = "<container‚Äëname>"
blob_inventory_file   = "<blob‚Äëinventory‚Äëfile‚Äëname>"      # ex: "inventory/2025‚Äë04‚Äë15/manifest.csv"
hierarchical_namespace_enabled = False                    # True si le compte est ADLS Gen2
# --------------------------------------------------------------------------- #

def read_blob_csv(file_path: str,
                  has_hns: bool,
                  schema: StructType | None = None):
    """
    Lit un fichier CSV dans Azure Blob Storage ou ADLS Gen2 et retourne un DataFrame.
    - file_path : chemin dans le conteneur (sans protocole).
    - has_hns   : True si hierarchical namespace (dfs.core.windows.net), sinon False.
    - schema    : sch√©ma Spark optionnel.
    """
    
    # 1Ô∏è‚É£ Choix du protocole + configuration de la cl√© d‚Äôacc√®s
    if has_hns:
        account_fqdn = f"{storage_account_name}.dfs.core.windows.net"
        spark.conf.set(f"fs.azure.account.key.{account_fqdn}", storage_account_key)
        uri = f"abfss://{container}@{account_fqdn}/{file_path}"
    else:
        account_fqdn = f"{storage_account_name}.blob.core.windows.net"
        spark.conf.set(f"fs.azure.account.key.{account_fqdn}", storage_account_key)
        uri = f"wasbs://{container}@{account_fqdn}/{file_path}"

    print(f"üì• Lecture du fichier via¬†: {uri}")

    # 2Ô∏è‚É£ Lecture effective
    reader = spark.read.option("header", "true")
    if schema is not None:
        reader = reader.schema(schema)
    else:
        reader = reader.option("inferSchema", "true")
    
    return reader.csv(uri)

# Exemple d‚Äôappel ----------------------------------------------------------------
# Si vous avez d√©j√† un sch√©ma d√©fini, d√©commentez et passez‚Äële √† la fonction.
# my_schema = StructType([
#     StructField("Name", StringType(), True),
#     StructField("Size", IntegerType(), True),
#     StructField("LastModified", StringType(), True)
# ])
df = read_blob_csv(blob_inventory_file,
                   has_hns=hierarchical_namespace_enabled,
                   schema=None)

df.show(5)
